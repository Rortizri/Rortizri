
MACHINE LEARNING FUNDAMENTALS


- In this part you will find code related to the fundamentals of Machine Learning. It will be constantly updated with modules to cover the main ML topics


Linear Regression using Gradient Descent.

- Linear Regression fits a linear model with coefficients, to minimize the residual sum of squares between the observed targets in the dataset, and the targets predicted by the linear approximation.
Gradient Descent is an iterative optimization algorithm to find the minimum of a function. Here that function is our Loss Function.


Quantile regression models 

- Shows the relationship between a set of predictor (independent) variables and specific percentiles (or "quantiles") of a target (dependent) variable, most often the median. It has two main advantages over Ordinary Least Squares regression:
Quantile regression makes no assumptions about the distribution of the target variable.
Quantile regression tends to resist the influence of outlying observations.

Random Forest.

- A random forest is a meta estimator that fits a number of classifying decision trees on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting.


K-Nearest Neighbors 

-K-Nearest Neighbors(or k-NN for short) is a simple machine learning algorithm that categorizes an input by using its k nearest neighbors.

Support-Vector Machines

-In Machine Learning, Support-Vector Machines (SVMs, also support-vector networks) are supervised learning models with associated learning algorithms that analyze data for classification and regression analysis.



<!---
Rortizri/Rortizri is a ✨ special ✨ repository because its `README.md` (this file) appears on your GitHub profile.
You can click the Preview link to take a look at your changes.
--->
